---
title: "Assignment 8"
author: "Sreedevi Kesavan"
date: "28/03/2021"
output:
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
For this assignment I have tried to re-create the `glm()` assignment from two weeks ago using Bayesian tools. I did not include the Male vs Female differences, because I was not able to find a way to combine continuous and discrete variables that did not break everything. 
```{r results = 'hide', warning=FALSE, message=FALSE}
#Packages Used ----
library(dplyr)
library(R2jags)
library(dotwhisker)
library(emdbook)
library(lattice)
```
I removed unnecessary columns from the data because the model was complaining a lot when I left them as is. I have re-analyzed the data using the frequentist approach below. 

```{r}

# Data and Frequentest model results ----
Plot_ready <- read.csv('Cor_data.csv')

Plot_ready <- Plot_ready %>% 
  select(-X, -TIME_PERIOD)
  
## BMB: glm with gaussian and identity link is identical to lm(); why not
## just use lm() ... ?
summary(glm(new_HIV~poly(M_to_C, 2),Plot_ready,family=gaussian(link = "identity")))
```

To create the model on the .bug file I regenerated the polynomial prediction. Since the rate of transmission from mother to child is per 100, I chose 50 as the mean and left the precision wide open. I was not too sure what would be more appropriate. I was unclear and sort of still am on whether the numbers within #dnorm() are the values of that parameter or the values w.r.t. to the response variable. I tried several different numbers large and small and the RHat and n.eff did not change much, so I was not sure how one evaluates the quality of one model over the other. In the end i just stuck to my original assumptions as stated below. 

I kept the distributions as normal primarily because that was what I assumed when I created the GLM about this dataset. I did try different distribution, but several of them particularly the uniform and logistic for some other types of data made the model complain a lot. I was not too clear how to interpret the errors for non-continuous data. 

```{r echo=FALSE}
# BUG FILE M_to_C ----
## BMB: you can cheat and preserve syntax highlighting: see ?R2jags::write.model
function()  {
   for (i in 1:N) {
     new_HIV[i] ~ dnorm(pred[i], tau)
     pred[i] <- mM_to_C*M_to_C[i]**2 + mM_to_C2*M_to_C[i] + int
         }
 mM_to_C ~ dnorm(50, .0001)
 mM_to_C2 ~ dnorm(50, .0001)
 int ~ dnorm(20, .0001)
 tau ~ dgamma(.001, .001)
}
```

**BMB:**: why pick these means for the priors? (0 seems more neutral; do you have prior data?
Note that the parameterization used by `poly()` (unless you specify `raw=TRUE`) will *not*
be `b_0 + b_1*x + b_2*x^2`, but an *orthogonal polynomial* (harder to interpret but 
numerically more stable)

I ran the model with JAGS and plotted the `dotwhisker` plot. Clearly the numbers don't match up well to the frequentest numbers from the start of this exercise. Perhaps my assumptions were too small? For a polynomial model like this one, I do wonder how one goes about plotting this the way the `geom_smooth()` plots it to the dataset. 

**BMB:** the difference in your fits is explained above (orthog polynomial vs raw polynomial)

```{r cmp_fits}
dd <- data.frame(x=1:3)
## orthogonal
zapsmall(model.matrix(~poly(x,2), data=dd))
## raw
model.matrix(~poly(x,2,raw=TRUE), data=dd)
```


I am tempted to go back and change the priors, but I think that defeats the purpose of them being priors. (**BMB**: indeed!) If that is the case, I wonder what one is meant to do at this point. How can I improve upon this to make it more meaningful to my dataset. In this particular example I did not include other predictor variable, I suspect the number may be more fluid if there was more of those as well. 

**BMB**: in general if there is something wrong with your model, adjusting the priors is not the way to fix it (although it can help if your model is *mostly* OK but runs into numerical problems).

```{r warning=FALSE, message=FALSE}
# R2jags model setup ----
set.seed(1234)
N <- 20
jags1 <- jags(model.file='ass8.bug',
              parameters=c("mM_to_C", "mM_to_C2", "int"),
              data = list(M_to_C = Plot_ready$M_to_C, new_HIV = Plot_ready$new_HIV, N = N),
              n.chains = 3,
              inits=NULL); jags1

mm <- as.mcmc.bugs(jags1$BUGSoutput)
## BMB: not sure why the first value is weird (won't affect inference because
## it's a single outlier, but messes up the plots)
## drop first sample of each chain (using mm[] preserves class structure)
mm[] <- lapply(mm, function(x) x[-1,])
print(xyplot(mm,layout=c(2,3)))
print(densityplot(mm,layout=c(2,3)))

print(dwplot(jags1)) 

```

**BMB**: grade 2: model is in fact wrong/weird but you did recognize it ...


